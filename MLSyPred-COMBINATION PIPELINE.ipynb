{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLSyPred Morgan Fingerprint 2048 Combinations PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to first convert the SMILES of all the drugs into Morgan Fingerprints to be able to perform the averages needed to determine synergy. \n",
    "The script can create averages on the Morgan Fingerprints of two compounds out of 79 compounds in total. \n",
    "The purpose of this script is to be able to perform average based on the presence of Morgan Fingerprints per pair of compounds There are 2048 bit Morgan fingerprints (features) and 79 drug compounds\n",
    "\n",
    "#56 of the drug compounds are in the training set \n",
    "#23 of the drug compounds are in the validation set \n",
    "\n",
    "The expected result for the average of Morgan Fingerprint 2048bit (features) is 0,0.5,1\n",
    "\n",
    "#'0' means that none of the 2 compounds have the Morgan fingerprints 2048\n",
    "#'0.5' means that only one compound has the Morgan fingerprints 2048\n",
    "#'1' means that both compounds have the Morgan fingerprints 2048\n",
    "\n",
    "The output of the column SMILE shows the SMILE of the first compound from the combination. \n",
    "The outcome is that those pairs of compounds sharing many Morgan Fingerprints in common are more likely to portray synergistic combinational therapy.\n",
    "\n",
    "Datasets used:\n",
    "\n",
    "Mason, D. J., Eastman, R. T., Lewis, R., Stott, I. P., Guha, R., & Bender, A. (2018). Using Machine Learning to Predict Synergistic Antimalarial Compound Combinations With Novel Structures. Frontiers in pharmacology, 9, 1096. https://doi.org/10.3389/fphar.2018.01096\n",
    "\n",
    "Mott, B. T., Eastman, R. T., Guha, R., Sherlach, K. S., Siriwardana, A., Shinn, P., McKnight, C., Michael, S., Lacerda-Queiroz, N., Patel, P. R., Khine, P., Sun, H., Kasbekar, M., Aghdam, N., Fontaine, S. D., Liu, D., Mierzwa, T., Mathews-Griner, L. A., Ferrer, M., Renslo, A. R., â€¦ Thomas, C. J. (2015). High-throughput matrix screening identifies synergistic and antagonistic antimalarial drug combinations. Scientific reports, 5, 13891. https://doi.org/10.1038/srep13891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages needed for the SMILE conversion (SCRIPT 1)\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import MACCSkeys\n",
    "\n",
    "#packages needed for the script to run (SCRIPT 2 & 3)\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas\n",
    "from itertools import combinations\n",
    "\n",
    "#other needed packages\n",
    "from numpy import unique     #needed in script 4\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE FILES\n",
    "\n",
    "#Input files\n",
    "\n",
    "\n",
    "\n",
    "inputTraining_S1 = 'smiles_trainingset.csv'\n",
    "#inputValidation_S1 = 'validation_2048_Morgan_trainingset.csv'\n",
    "\n",
    "#OUTPUT FILES\n",
    "outputTraining_S1 = 'smiles_validationset.csv' \n",
    "#outputValidation_S1 = 'validation_2048_Morgan_validationset.csv'\n",
    "\n",
    "#specify if MACCSkeys or Morgan Fingerprints\n",
    "\n",
    "# if MACCSkeys please assign maccskey = 1 and assign columns  (167)\n",
    "# if Morgan please assign morgan = 1 and assign columns in columnas (1024 0r 2048)\n",
    "\n",
    "var_maccskey = 0\n",
    "var_morgan  = 1\n",
    "\n",
    "columnas = 2048\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataModel(input, output):\n",
    "    \n",
    "    # open the input file in read mode\n",
    "    with open(input, 'r') as file_handle:\n",
    "        # read file content into list\n",
    "        lines = file_handle.readlines()\n",
    "        #read file content into list\n",
    "        counter_lines = (len(lines) )\n",
    "\n",
    "    # OUTPUT FILE in write mode\n",
    "    OUTFILES1 = open(output, 'w')\n",
    "    \n",
    "    \n",
    "    #######\n",
    "    #write number of columns MACCS(167)  or Morgan (1024 0 2048) without counting the first two columns (compound & SMILES)    columnas = 2048\n",
    "    #columns=2048\n",
    "    ########\n",
    "\n",
    "\n",
    "    miscolumns = (\"Compound,\" + \"SMILES\")\n",
    "    for col in range(1,columns+1):\n",
    "        miscolumns = str(miscolumns) + \",\" + str(col)\n",
    "    lineoutput=str(miscolumns)+\"\\n\"\n",
    "    OUTFILES1.write((lineoutput)) \n",
    "    #print(lineoutput)\n",
    "\n",
    "    #For the csv to start reading at row 2\n",
    "    for n in range(1,counter_lines) : \n",
    "    #Determine everything that is in a single row within the csv. In this case the name of the compound and the SMILES\n",
    "        milinea = lines[n].split(\",\")\n",
    "    #Determines column 0 within csv as a variable that would be the compound names\n",
    "        var0=milinea[0]\n",
    "    #Determines column 1 within the csv as a variable that in this case would be the SMILES\n",
    "        var1=milinea[1]\n",
    "    #Assigns a variable for the change from SMILE format to hexadecimal format of each of the compounds\n",
    "        tmp = Chem.MolFromSmiles(var1)\n",
    "        if var_morgan == 1:\n",
    "            #Assign a variable for the hexadecimal format change to Morgan Fingerprint 2048\n",
    "            fp1 = AllChem.GetMorganFingerprintAsBitVect(tmp, radius=2, nBits=columnas)\n",
    "        if var_maccskey == 1:\n",
    "            fp1 = MACCSkeys.GenMACCSKeys(tmp)\n",
    "    #Assign a variable to know the number of Morgan Fingerprint 2048 bit generated\n",
    "        largo=len(fp1)\n",
    "        #print(fp1)\n",
    "        #print(largo)\n",
    "    #This created variable takes into consideration both the name of the compound and the SMILE of the compound within the csv separated by a comma        \n",
    "    lineoutput = str(var0) + \",\" + str(var1)\n",
    "    #Creating this variable removes a document row from the output\n",
    "        lineoutput=lineoutput.strip()\n",
    "    # i is going to start counting from 1 to 2047. This is necessary because if it does not count from 0 to 2047, creating 2048 features instead of 2047, one of them being empty.        \n",
    "        for i in range(largo):\n",
    "            var2= int((fp1[i]))\n",
    "        #This variable is created so that the output has the name of the compounds, the SMILES and the Morgan Fingerprints\n",
    "            lineoutput=lineoutput+\",\"+str(var2)\n",
    "    #This variable allows the output to present the information of each compound in one line below the other. \n",
    "        lineoutput=lineoutput+\"\\n\"\n",
    "    #Write output file\n",
    "        OUTFILES1.write((lineoutput))  \n",
    "    OUTFILES1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff778259c60>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff77826e620>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff769a1cc10>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff769a1c3a0>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff778259c60>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff77826e620>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff769a1c3a0>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff778259c60>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff77826e620>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff769a1cc10>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff769a1c3a0>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff778259c60>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff769a1cc10>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff77826e620>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff769a1c3a0>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff778259c60>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff77826e620>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff769a1cc10>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff769a1c3a0>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff778259c60>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff77826e620>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff769a1cc10>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff769a1c3a0>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff77826e620>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff769a1cc10>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff778259c60>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff769a1c3a0>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff769a1cc10>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff778259c60>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff77826e620>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff769a1c3a0>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff769a1cc10>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff778259c60>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff769a1c3a0>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff769a1cc10>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff77826e620>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff778259c60>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff769a1cc10>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff77826e620>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff778259c60>\n",
      "2048\n",
      "<rdkit.DataStructs.cDataStructs.ExplicitBitVect object at 0x7ff769a1c3a0>\n",
      "2048\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    ##TRAINING SET (MORGAN2048) (WITH 56 COMPOUNDS)\n",
    "    dataModel(inputTraining_S1, outputTraining_S1)\n",
    "\n",
    "    ##VALIDATION SET (SYNERGISM) (WITH 23 COMPOUNDS)\n",
    "    dataModel(inputValidation_S1, outputValidation_S1)\n",
    "\n",
    "#Executes all code in main\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script #2 \n",
    "\n",
    "Read outputs script 1.  and the The output file is the drug combination ID (e.g. Drug1_Drug2), along with computed feature values as:\n",
    "\t0.5 if one of the two drugs include the fingerprints equal to 1, i.e. {Drug_1=1,Drug_2=0 or Drug_1=0,Drug_2=1  \n",
    "\t0 if the two drugs include the fingerprints equal to 0, i.e. {Drug_1=0,Drug_2=0\n",
    "\t1 if the two drugs include the fingerprints equal to 1, i.e. {Drug_1=1,Drug_2=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE FILES SCRIPT 2\n",
    "\n",
    "#DEFINE FILES\n",
    "\n",
    "#Input files\n",
    "inputTraining_S2 = outputTraining_S1\n",
    "#inputValidation_S2 = outputValidation_S1\n",
    " \n",
    "#OUTPUT FILES  \n",
    "outputTraining_S2 = 'OUTS2.csv'\n",
    "#outputValidation_S2 = 'validation_set_2048_Morgan_OUTS2.csv'\n",
    "\n",
    "\n",
    "\n",
    "#Placeholder variables if number of columns changes\n",
    "COL_COUNT1=1\n",
    "COL_COUNT2= columns + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to open input and create output\n",
    "def dataModel(input, output):\n",
    "\n",
    "    # OUTPUT FILE in write mode\n",
    "    OUTFILE = open(output, 'w')\n",
    "\n",
    "    # open the input file in read mode\n",
    "    with open(input, 'r') as file_handle:\n",
    "        # read file content into list\n",
    "        lines = file_handle.readlines()\n",
    "    #lineOutput = lines[0] + lines[1] + lines[2] + lines[3] + lines[4]\n",
    "    lineOutput=lines[0]\n",
    "    \n",
    "    # write in file\n",
    "    OUTFILE.write(lineOutput)\n",
    "\n",
    "    # stop editing the file\n",
    "    OUTFILE.close()\n",
    "\n",
    "    # establish a dataframe with the input file\n",
    "    df = pandas.read_csv(input)\n",
    "    #lineOutput = df.iloc[0:4]\n",
    "    lineOutput = df.iloc[0]\n",
    "\n",
    "    # only select starting from row 0 from the df dataframe and creates dff (an updated version of df)\n",
    "    #dff = df.iloc[4:]\n",
    "    dff = df.iloc[0:]\n",
    "\n",
    "    # OUTPUT FILE in append mode (add information without overriding the file)\n",
    "    OUTFILE = open(output, 'a')\n",
    "\n",
    "    # names each columns in dff (the updated version of df)\n",
    "    dff_columns = ['ID', 'Morgan fingerprint or MACCSKeys']\n",
    "    for i in range(COL_COUNT1,COL_COUNT2):\n",
    "        dff_columns.append(str(i))\n",
    "    dff.columns = dff_columns\n",
    "\n",
    "    # resets the index in dff\n",
    "    dff = dff.reset_index(drop=True)\n",
    "\n",
    "    # dff2 is dff without the column names of 'ID' and \"Morgan fingerprint 2048 index'\n",
    "    dff2 = dff.drop(['ID', 'Morgan fingerprint or MACCSKeys'], axis=1)\n",
    "    dff2_columns = len(dff2.columns)\n",
    "\n",
    "    # reindex dff2\n",
    "    dff2 = dff2.reset_index(drop=True)\n",
    "\n",
    "    # creates a list with all the combinations of compounds selecting all the rows from column 0\n",
    "    # no combination pair is repeated\n",
    "    cc = list(combinations(dff.iloc[:, 0], 2))\n",
    "\n",
    "\n",
    "    for i in cc:\n",
    "\n",
    "        # selecting first compound\n",
    "        comp1 = i[0]\n",
    "\n",
    "        # selecting second compond\n",
    "        comp2 = i[1]\n",
    "\n",
    "        # establishes the index value of comp1\n",
    "        x = dff[dff['ID'] == comp1].index.values\n",
    "\n",
    "        # establishes the index value of comp1\n",
    "        y = dff[dff['ID'] == comp2].index.values\n",
    "\n",
    "        # var2 shows the SMILES of the first compound from the pair of compounds\n",
    "        var2 = [s for s in lines if comp1 in s]\n",
    "\n",
    "        # turn var2 into a string\n",
    "        var2 = str(var2)\n",
    "\n",
    "        # split var2 in ',' (commas)\n",
    "        var2 = var2.split(',')\n",
    "\n",
    "        # establish Morgan as the first item in var2\n",
    "        Morgan = var2[1]\n",
    "\n",
    "        # creating dff3 by selecting integers of 'x' and 'y' as rows and all columns from dff2\n",
    "        dff3 = dff2.iloc[[int(x), int(y)], :]\n",
    "        lineaver = []\n",
    "\n",
    "        # range generates a series of number from 0 to 2048 (number of columns in this case)\n",
    "        for j in range(0, dff2_columns):\n",
    "\n",
    "            # select all the cells with numerical values of the first compound in row '0' in dff3\n",
    "            value1 = dff3.iloc[0, j]\n",
    "\n",
    "            # selecting all the cells with numerical values of the second compound in row '1' in dff3\n",
    "            value2 = dff3.iloc[1, j]\n",
    "\n",
    "            # creating the variable to create the average of all the columns from row '0' and '1'\n",
    "            Total = (int(value1) + int(value2)) / 2\n",
    "\n",
    "            # perform rounding for whole numbers such as '0' and '1' only; not on '0.5'\n",
    "            if Total == 0.0:\n",
    "                Total = 0\n",
    "            if Total == 1.0:\n",
    "                Total = 1\n",
    "\n",
    "            # make the result of Total into string\n",
    "            Total = str(Total)\n",
    "\n",
    "            # append Total into lineaver\n",
    "            lineaver.append(Total)\n",
    "\n",
    "        # join all the averages from all the pairs of compounds together\n",
    "        lineaver = ', '.join(map(str, lineaver))\n",
    "\n",
    "        # add the pair of compounds with the MACCS in string and the average calculations in string in a variable\n",
    "        lineOutput = '(' + comp1 + '+' + comp2 + ')' + ',' + str(Morgan) \\\n",
    "            + ',' + str(lineaver) + '\\n'\n",
    "\n",
    "        # write in output file by changing the type of lineOutput to string\n",
    "        OUTFILE.write(str(lineOutput))\n",
    "\n",
    "    # closing output file\n",
    "    OUTFILE.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to release output from input through function dataModel\n",
    "def main():\n",
    "\n",
    "    ##TRAINING SET (Morgan fingerprint 2048) (WITH 56 COMPOUNDS)\n",
    "    dataModel(inputTraining_S2, outputTraining_S2)\n",
    "\n",
    "    ##VALIDATION SET (SYNERGISM) (WITH 23 COMPOUNDS)\n",
    "    dataModel(inputValidation_S2, outputValidation_S2)\n",
    "\n",
    "#Executes all code in main\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script 3 \n",
    "\n",
    "Add synergy value to create files to process in ML\n",
    "Input = output of script 2 and a file with synergy between drug 1 and 2 (external file)\n",
    "The output of script is the result of merging the features (fingerprints) previously created of the training validation sets with the existing labels from the external file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with Training file\n",
      "Output File header created\n",
      "Processing Training File\n",
      "Total of combinations not found = 749\n",
      "Total of lines wrote in file without header  = 71\n",
      "Total lines read = 821\n",
      "##################################\n",
      "End of processing training files \n",
      "\n",
      "##################################\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "######################################################################\n",
    "#     DEFINE SECTION\n",
    "#   DEFINE FILES NAME AND NUMBER OF COLUMNS IF APPLY\n",
    "\n",
    "#INPUT FILES\n",
    "\n",
    "inputTraining_S3 = outputTraining_S2 \n",
    "#inputValidation_S3= outputValidation_S2\n",
    "\n",
    "INPUT_SYNERGY_TRAINING = 'COMBINATIONS_SYNERGY_TRAINING_3D7.csv'\n",
    "#INPUT_SYNERGY_VALIDATION = 'COMBINATIONS_SYNERGY_VALIDATION_3D7.csv'\n",
    "\n",
    "\n",
    "#OUTPUT FILES\n",
    "\n",
    "OUTPUT_TRAINING_S3 = 'OUTS3.CSV'\n",
    "#OUTPUT_VALIDATION_S3 = 'VALIDATION_SET_ML_2048_Morgan_OUTS3.CSV'\n",
    "\n",
    "\n",
    "#Placeholder variables if number of columns changes\n",
    "COL_COUNT1 = 1\n",
    "COL_COUNT2 = columns + 1\n",
    "\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "######################    BEGIN FUNCTIONS     #############################\n",
    "##########################################################################\n",
    "\n",
    "##########################################################################\n",
    "##############           PRINT HEADER FUNCTION              ##############\n",
    "##########################################################################\n",
    "\n",
    "def header(output):\n",
    "\n",
    "    OUTFILE = open(output, 'w')\n",
    "    #write header in file\n",
    "    header_columns = ['SYNERGY', 'ID', 'Morgan fingerprint or MACCSkeys']\n",
    "\n",
    "    for i in range(COL_COUNT1,COL_COUNT2):\n",
    "        header_columns.append(str(i))\n",
    "    header_columns = (', '.join(map(str,header_columns)))\n",
    "    lineOutput = str(header_columns) +  \"\\n\"\n",
    "\n",
    "    #print((lineOutput))\n",
    "    OUTFILE.write(lineOutput)\n",
    "    OUTFILE.close()\n",
    "    print(\"Output File header created\")\n",
    "\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "#### FUNCTION TO JOIN SYNERGY VALUE TO COMBINATION FILE #####\n",
    "##########################################################################\n",
    "\n",
    "def ADD_SYNERGY(input1, input2, output):\n",
    "\n",
    "    #OPEN OUTPUT FILE AGAIN AFTER PRINT HEADER THIS TIME AS APPEND TO ADD NEW LINES\n",
    "    #WITH COMBINATIONS AND SYNERGY\n",
    "    OUTFILE = open(output, 'a')\n",
    "\n",
    "    #read file in df format - this file contains if combinations have synergy\n",
    "    df = pandas.read_csv(input1)\n",
    "    #Convert Yes and No in 1 and 0 for ML\n",
    "    df['SYNERGY(Yes/No)'].replace('Yes', '1',inplace=True)\n",
    "    df['SYNERGY(Yes/No)'].replace('No', '0',inplace=True)\n",
    "    df = df.fillna(0)\n",
    "    #print(df)\n",
    "    \n",
    "    \n",
    "    # Open combinations file with the other information\n",
    "    with open(input2, 'r') as file_handle:\n",
    "        # read file content into list\n",
    "        lines = file_handle.readlines()\n",
    "         \n",
    "\n",
    "    #counter of lines (use as counter to skip headers of input2 file)\n",
    "    lread = 0\n",
    "    lines_printed = 0\n",
    "    not_found = 0\n",
    "\n",
    "    for line in lines :\n",
    "        lread = lread + 1\n",
    "        \n",
    "        if lread > 1  : #\n",
    "            line = line.split(\",\")  #split line\n",
    "            #print(line)\n",
    "            #extract the compounds to process\n",
    "            comp1, comp2 = line[0].split('+')\n",
    "            comp1 = comp1[1:]\n",
    "            comp2 = comp2[:-1]\n",
    "            #print(comp1 + \"/ \" + comp2)\n",
    "            \n",
    "            #localize line in synergy df with the 2 compound\n",
    "            df2 = df[(df['COMPOUND_1']  == comp1) & (df['COMPOUND_2']  == comp2)]\n",
    "            \n",
    "            \n",
    "            if df2.empty:\n",
    "                df2 = df[(df['COMPOUND_1']  == comp2) & (df['COMPOUND_2']  == comp1)]\n",
    "                        \n",
    "            if not df2.empty :  \n",
    "                #print(df_status)\n",
    "                synergy = df2.iloc[0].at['SYNERGY(Yes/No)'] #extract synergy value               \n",
    "            \n",
    "                #convert line for print\n",
    "                line = (','.join(map(str,line)))\n",
    "\n",
    "                #prepare line to print or write in file\n",
    "                lineOutput = str(synergy) + \",\"  + str(line)\n",
    "                OUTFILE.write(lineOutput)\n",
    "                \n",
    "                lines_printed = lines_printed + 1\n",
    "                #print(comp1 + \" / \" + comp2 + \"-- found wrote in file  ****** \\n\")\n",
    "            else:\n",
    "                #print(comp1 + \" / \" + comp2 + \" -- not found and not wrote in file \\n\")\n",
    "                not_found = not_found + 1\n",
    "\n",
    "    # closing output file\n",
    "    print(\"Total of combinations not found = \" + str(not_found))\n",
    "    print(\"Total of lines wrote in file without header  = \" + str(lines_printed))\n",
    "    print(\"Total lines read = \" + str(lread))\n",
    "    OUTFILE.close()\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "######      function to create file to join synergy file and   ###########\n",
    "######      combination file and use for ML File               ###########\n",
    "##########################################################################\n",
    "\n",
    "def add_synergy_value():\n",
    "\n",
    "\n",
    "    \n",
    "    ##TRAINING SET (SYNERGISM 3D7) (WITH 56 COMPOUNDS)\n",
    "    print(\"Working with Training file\")\n",
    "    header(OUTPUT_TRAINING_S3)\n",
    "    print(\"Processing Training File\")\n",
    "    ADD_SYNERGY(INPUT_SYNERGY_TRAINING, inputTraining_S3, OUTPUT_TRAINING_S3 )\n",
    "    print(\"##################################\" )\n",
    "    print(\"End of processing training files \\n\" )\n",
    "    print(\"##################################\" )\n",
    "    \n",
    "    \n",
    "    ##VALIDATION SET (MORGAN2048 3D7) (WITH 23 COMPOUNDS)\n",
    "    #print(\"Working with Validation file\")\n",
    "    #header(OUTPUT_VALIDATION_S3)\n",
    "    #print(\"Processing Validation File\")\n",
    "    #ADD_SYNERGY(INPUT_SYNERGY_VALIDATION, inputValidation_S3, OUTPUT_VALIDATION_S3 )\n",
    "    #print(\"###################################\" )\n",
    "    #print(\"End of processing Validations files\" )\n",
    "    #print(\"################################### \\n\" )\n",
    "\n",
    "    \n",
    "#########################\n",
    "##############                 BEGIN                        ##############  \n",
    "##########################################################################\n",
    "\n",
    "#Executes all code\n",
    "\n",
    "add_synergy_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script 4\n",
    "This module perform a data cleaning of the raw training and validation datasets. First, the features (file columns) with the same values for all drug combinations are deleted from the training set.  After the features (file columns) were removed in the training data set, the same features (columns) were deleted in the validation set. The output file was data without unmeaningful features (columns). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#define input and output files\n",
    "\n",
    "# INPUT FILES\n",
    "\n",
    "INPUT_TRAINING_S4 =  OUTPUT_TRAINING_S3 \n",
    "#INPUT_VALIDATION_S4 = OUTPUT_VALIDATION_S3\n",
    "\n",
    "\n",
    "# OUTPUT  FILES\n",
    "\n",
    "OUTFILE_TRAINING_S4 = 'UPDATED_OUTS4.CSV'\n",
    "OUTFILE_VALIDATION_S4 = 'VALIDATION_SET_ML_2048_Morgan_UPDATED_OUTS4.CSV' \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71, 2051)\n",
      "Index([' 1', ' 3', ' 4', ' 9', ' 10', ' 12', ' 16', ' 17', ' 18', ' 19',\n",
      "       ...\n",
      "       ' 2032', ' 2033', ' 2037', ' 2038', ' 2040', ' 2041', ' 2042', ' 2044',\n",
      "       ' 2046', ' 2047'],\n",
      "      dtype='object', length=1199)\n",
      "(71, 852)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'INPUT_VALIDATION_S4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-c70d083126d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#establish a dataframe with the input file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mdf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_VALIDATION_S4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#df2=df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'INPUT_VALIDATION_S4' is not defined"
     ]
    }
   ],
   "source": [
    "# PROCESS TRAINING FILE\n",
    "\n",
    "#establish a dataframe with the input file\n",
    "df2=pd.read_csv(INPUT_TRAINING_S4)\n",
    "\n",
    "#df2=df\n",
    "   \n",
    "print(df2.shape)\n",
    "nunique=df2.apply(pd.Series.nunique)\n",
    "cols_to_del=nunique[nunique==1].index\n",
    "print(cols_to_del)\n",
    "df2.drop(cols_to_del,axis=1)\n",
    "df3=df2.drop(cols_to_del,axis=1)\n",
    "print(df3.shape)\n",
    "\n",
    "df3.to_csv(OUTFILE_TRAINING_S4, index=False,encoding='utf8')\n",
    "\n",
    "# PROCESS VALIDATION FILE\n",
    "\n",
    "#establish a dataframe with the input file\n",
    "df2=pd.read_csv(INPUT_VALIDATION_S4)\n",
    "\n",
    "#df2=df  \n",
    "\n",
    "print(cols_to_del)\n",
    "df3=df2.drop(cols_to_del,axis=1)\n",
    "print(df3.shape)\n",
    "\n",
    "df3.to_csv(OUTFILE_VALIDATION_S4, index=False,encoding='utf8')\n",
    "\n",
    "\n",
    "#CLOSE FILES\n",
    " \n",
    "#OUTFILE_TRAINING.close()\n",
    "#OUTFILE_VALIDATION.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
